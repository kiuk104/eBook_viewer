import { GoogleGenerativeAI } from "@google/generative-ai";
import { getGeminiKey } from './settings.js';

/**
 * í…ìŠ¤íŠ¸ë¥¼ ë¬¸ë‹¨ ë‹¨ìœ„ë¡œ ì•ˆì „í•˜ê²Œ ìë¥´ëŠ” í•¨ìˆ˜
 */
function chunkText(text, maxLength) {
    const chunks = [];
    let currentChunk = "";
    const paragraphs = text.split(/\n\s*\n/); // ë¹ˆ ì¤„ ê¸°ì¤€ìœ¼ë¡œ ë¬¸ë‹¨ ë¶„ë¦¬

    for (const paragraph of paragraphs) {
        if (paragraph.length > maxLength) {
            if (currentChunk) {
                chunks.push(currentChunk);
                currentChunk = "";
            }
            for (let i = 0; i < paragraph.length; i += maxLength) {
                chunks.push(paragraph.slice(i, i + maxLength));
            }
        } else {
            if (currentChunk.length + paragraph.length + 2 < maxLength) {
                currentChunk += (currentChunk ? "\n\n" : "") + paragraph;
            } else {
                chunks.push(currentChunk);
                currentChunk = paragraph;
            }
        }
    }
    if (currentChunk) chunks.push(currentChunk);
    return chunks;
}

export async function cleanTextWithAI(text, onProgress) {
    const apiKey = getGeminiKey();
    if (!apiKey) {
        alert("ì„¤ì •ì—ì„œ Google Gemini API í‚¤ë¥¼ ë¨¼ì € ë“±ë¡í•´ì£¼ì„¸ìš”!");
        throw new Error("API Key missing");
    }

    const genAI = new GoogleGenerativeAI(apiKey);
    const CHUNK_SIZE = 6000; 
    const chunks = chunkText(text, CHUNK_SIZE);
    const totalChunks = chunks.length;
    let combinedResult = "";

    console.log(`ğŸ“ í…ìŠ¤íŠ¸ ë¶„í•  ì²˜ë¦¬ ì‹œì‘: ì´ ${totalChunks}ê°œ êµ¬ì—­`);

    // ëª¨ë¸ ìš°ì„ ìˆœìœ„
    const modelsToTry = [
        "gemini-2.0-flash-exp",
        "gemini-1.5-flash-002",
        "gemini-1.5-flash"
    ];

    for (let i = 0; i < totalChunks; i++) {
        const chunk = chunks[i];
        const isFirstChunk = (i === 0);
        
        if (onProgress) {
            const percent = Math.round(((i + 1) / totalChunks) * 100);
            onProgress(`AI ë³€í™˜ ì¤‘... (${i + 1}/${totalChunks} êµ¬ì—­, ${percent}%)`);
        }

        // [ìˆ˜ì •ëœ í”„ë¡¬í”„íŠ¸] ì‹œê°ì  ì°Œêº¼ê¸° ì œê±° ìš”ì²­
        let systemPrompt = "";
        if (isFirstChunk) {
            systemPrompt = `
            ë‹¹ì‹ ì€ ì „ë¬¸ ì „ìì±… í¸ì§‘ìì…ë‹ˆë‹¤.
            
            [í•„ìˆ˜ ê·œì¹™ - ì—„ê²© ì¤€ìˆ˜]
            1. **ì„œì§€ ì •ë³´ í‘œ**: ë¬¸ì„œ ìµœìƒë‹¨ì—ë§Œ ì €ì/ì¶œíŒì‚¬ ì •ë³´ë¥¼ 'ë§ˆí¬ë‹¤ìš´ í‘œ'ë¡œ ì‘ì„±í•˜ê³ , ë°”ë¡œ ì•„ë˜ '---' êµ¬ë¶„ì„ ì„ ë„£ìœ¼ì„¸ìš”.
            2. **ë³¸ë¬¸ ìŠ¤íƒ€ì¼**: ì¼ë°˜ì ì¸ ì†Œì„¤ì±…ì²˜ëŸ¼ ì‘ì„±í•˜ì„¸ìš”.
               - **ì ˆëŒ€** ëŒ€í™”ë¬¸ì— ì¸ìš©êµ¬ ê¸°í˜¸('>')ë¥¼ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”. (í™”ë©´ì— íšŒìƒ‰ ì¤„ì´ ìƒê²¨ ì§€ì €ë¶„í•©ë‹ˆë‹¤)
               - **ì ˆëŒ€** ì¤„ë°”ê¿ˆì„ ìœ„í•´ ë°±ìŠ¬ë˜ì‹œ('\\')ë‚˜ íŒŒì´í”„('|') ê¸°í˜¸ë¥¼ ë„£ì§€ ë§ˆì„¸ìš”.
            3. **ë¬¸ë‹¨ ê°„ê²©**: ë¬¸ë‹¨ê³¼ ë¬¸ë‹¨ ì‚¬ì´ëŠ” ë°˜ë“œì‹œ **ë¹ˆ ì¤„ í•˜ë‚˜(ì—”í„° ë‘ ë²ˆ)**ë¥¼ ë¹„ì›Œì£¼ì„¸ìš”.
            4. **ë‚´ìš© ìœ ì§€**: ì›ë¬¸ ë‚´ìš©ì„ ì‚­ì œí•˜ê±°ë‚˜ ìš”ì•½í•˜ì§€ ë§ê³  ê·¸ëŒ€ë¡œ ì‚´ë¦¬ì„¸ìš”.
            `;
        } else {
            systemPrompt = `
            ë‹¹ì‹ ì€ ì†Œì„¤ í¸ì§‘ìì…ë‹ˆë‹¤. ì•ë¶€ë¶„ì— ì´ì–´ì§€ëŠ” í…ìŠ¤íŠ¸ë¥¼ ì •ë¦¬ ì¤‘ì…ë‹ˆë‹¤.
            
            [í•„ìˆ˜ ê·œì¹™]
            1. **ë©”íƒ€ë°ì´í„°/í‘œ ê¸ˆì§€**: ì•ë¶€ë¶„ì—ì„œ ì´ë¯¸ ì‘ì„±í–ˆìœ¼ë‹ˆ, ì—¬ê¸°ì„œëŠ” ì ˆëŒ€ í‘œë¥¼ ë§Œë“¤ì§€ ë§ˆì„¸ìš”.
            2. **ë³¸ë¬¸ ìŠ¤íƒ€ì¼**:
               - ëŒ€í™”ë¬¸ì— ì¸ìš©êµ¬ ê¸°í˜¸('>') ì‚¬ìš© ê¸ˆì§€.
               - ì¤„ë°”ê¿ˆìš© íŠ¹ìˆ˜ê¸°í˜¸('\\', '|') ì‚¬ìš© ê¸ˆì§€.
            3. **ë¬¸ë‹¨ ê°„ê²©**: ë¬¸ë‹¨ ì‚¬ì´ì—ëŠ” ë¹ˆ ì¤„ì„ í•˜ë‚˜ ë„£ì–´ì£¼ì„¸ìš”.
            4. ë‚´ìš© ëŠê¹€ ì—†ì´ ìì—°ìŠ¤ëŸ½ê²Œ ì´ì–´ì„œ ì‘ì„±í•˜ì„¸ìš”.
            `;
        }

        let chunkSuccess = false;
        let chunkResult = "";

        for (const modelName of modelsToTry) {
            try {
                const model = genAI.getGenerativeModel({ 
                    model: modelName,
                    systemInstruction: systemPrompt 
                });

                const result = await model.generateContent({
                    contents: [{ role: "user", parts: [{ text: chunk }] }],
                    generationConfig: {
                        maxOutputTokens: 8192,
                        temperature: 0.7,
                    }
                });

                const response = await result.response;
                chunkResult = response.text();
                
                if (chunkResult) {
                    chunkSuccess = true;
                    combinedResult += chunkResult + "\n\n";
                    break; 
                }
            } catch (error) {
                console.warn(`âš ï¸ [Chunk ${i+1}] ${modelName} ì‹¤íŒ¨:`, error);
            }
        }

        if (!chunkSuccess) {
            alert(`ë³€í™˜ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. (${i+1}ë²ˆì§¸ êµ¬ì—­)\në„¤íŠ¸ì›Œí¬ ìƒíƒœë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.`);
            throw new Error("Chunk processing failed");
        }
        
        await new Promise(r => setTimeout(r, 500));
    }

    // [í›„ì²˜ë¦¬] AIê°€ ë‚¨ê¸´ ì°Œêº¼ê¸° ë¬¸ì ê°•ì œ ì²­ì†Œ (RegEx)
    // 1. í™€ë¡œ ìˆëŠ” ë°±ìŠ¬ë˜ì‹œ(\) ì œê±°
    combinedResult = combinedResult.replace(/^\s*\\\s*$/gm, "");
    // 2. í™€ë¡œ ìˆëŠ” íŒŒì´í”„(|) ì œê±°
    combinedResult = combinedResult.replace(/^\s*\|\s*$/gm, "");
    // 3. 3ì¤„ ì´ìƒì˜ ê³¼ë„í•œ ê³µë°±ì„ 2ì¤„ë¡œ ì¶•ì†Œ
    combinedResult = combinedResult.replace(/\n{3,}/g, "\n\n");

    return combinedResult;
}